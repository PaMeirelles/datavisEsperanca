import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
import random
import math
from scipy.optimize import minimize

# --- Configuration for Category Selection ---
# Choose the column you want to use for clustering nodes.
chosen_category_column = 'ethnicity' # <--- CHANGE THIS LINE TO SELECT YOUR CATEGORY

# --- Configuration for Attributes used in Centroid Optimization ---
# Dynamically read all column names from the DataFrame and exclude specific ones.
# These columns will be used to define the "attribute space" for centroids.
exclude_from_attributes = ['id', 'nomeEleitoral', 'cpf', 'redeSocial', 'dataNascimento', 'election_year', 'idLegislatura', chosen_category_column]

# Load data from CSV. Assuming 'enriched_congresspeople.csv' is in the same directory.
try:
    df = pd.read_csv("./enriched_congresspeople.csv")
except FileNotFoundError:
    print("Error: 'enriched_congresspeople.csv' not found. Please make sure the file is in the correct directory.")
    exit()

# Get all columns from the DataFrame
all_df_columns = df.columns.tolist()

# Filter out the excluded columns to get your attribute columns
attribute_columns = [col for col in all_df_columns if col not in exclude_from_attributes]

print("Education", df["education"].dropna().unique())

# --- Data Preprocessing ---
# We need unique "politicians" as nodes. The 'id' column uniquely identifies a politician.
node_data = df.groupby('id').first().reset_index()

# Select relevant columns for node creation and attributes
required_cols = ['id', 'nomeEleitoral', chosen_category_column] + attribute_columns
for col in required_cols:
    if col not in node_data.columns:
        print(f"Error: Required column '{col}' not found in the DataFrame. Please check your CSV.")
        print(f"Available columns are: {node_data.columns.tolist()}")
        exit()

node_data = node_data[required_cols].copy()
node_data.rename(columns={chosen_category_column: 'category'}, inplace=True) # Rename for generic use

# Handle potential NaN values in the chosen category
node_data['category'].fillna('UNDEFINED', inplace=True)

# Handle NaN values in attribute columns for consistent one-hot encoding
for col in attribute_columns:
    if node_data[col].dtype == 'object': # Only for categorical columns
        node_data[col].fillna('UNKNOWN', inplace=True)
    elif pd.api.types.is_numeric_dtype(node_data[col]):
        node_data[col].fillna(node_data[col].mean(), inplace=True) # Or median, or 0, depending on context

# Create one-hot encoded attributes for each node
# This will be used to calculate attribute centroids
node_attributes_df = pd.get_dummies(node_data[attribute_columns], columns=attribute_columns, prefix_sep='_')

# Combine with node_data for easy lookup
node_data = pd.concat([node_data, node_attributes_df], axis=1)

# Create a mapping from 'id' to category, name, and attribute vector for quick lookup
id_to_category = node_data.set_index('id')['category'].to_dict()
id_to_name = node_data.set_index('id')['nomeEleitoral'].to_dict()
# Map 'id' to its attribute vector (numpy array)
id_to_attribute_vector = {row['id']: row[node_attributes_df.columns].to_numpy() for index, row in node_data.iterrows()}

# --- 1. Create a graph ---
G = nx.Graph()

# Add nodes with their categorical attributes and attribute vectors
for index, row in node_data.iterrows():
    node_id = row['id']
    category = row['category']
    attributes = id_to_attribute_vector[node_id] # Get the numpy array of attributes
    G.add_node(node_id, category=category, name=row['nomeEleitoral'], attributes=attributes)

# --- Define Edges ---
unique_election_years = df['election_year'].unique()

for year in unique_election_years:
    politicians_in_year = df[df['election_year'] == year]['id'].unique()
    for i, p1_id in enumerate(politicians_in_year):
        for p2_id in politicians_in_year[i+1:]:
            if p1_id != p2_id:
                G.add_edge(p1_id, p2_id)

print(f"Number of nodes: {G.number_of_nodes()}")
print(f"Number of edges: {G.number_of_edges()}")

if G.number_of_nodes() == 0:
    print("No nodes found in the graph. Check your data and node creation logic.")
    exit()
if G.number_of_edges() == 0:
    print("No edges found in the graph. The edge creation logic might need adjustment for your data.")


# ====================================================================
# START OF MODIFICATIONS ONLY TO CENTROID PLACEMENT LOGIC
# ====================================================================

# --- Optimization Configuration for Centroid Placement ---
# This is now the FIXED radius for centroids on the circumference.
OPTIMIZATION_RADIUS = 5.0 # <--- NEW: Fixed radius for all centroids. Tune this.

# --- Helper Functions for Centroid Optimization ---
def calculate_attribute_centroids(graph):
    """
    Calculates the centroid of attributes for each category in the graph.
    Assumes each node has a 'category' and 'attributes' (numpy array of numerical values).
    """
    category_attribute_sums = {}
    category_node_counts = {}

    for node_id in graph.nodes():
        node_data = graph.nodes[node_id]
        category = node_data.get('category')
        attributes = node_data.get('attributes') # This should already be a NumPy array

        if category and attributes is not None:
            if category not in category_attribute_sums:
                category_attribute_sums[category] = np.zeros_like(attributes)
                category_node_counts[category] = 0

            category_attribute_sums[category] += attributes
            category_node_counts[category] += 1

    attribute_centroids = {}
    for category, attr_sum in category_attribute_sums.items():
        attribute_centroids[category] = attr_sum / category_node_counts[category]

    return attribute_centroids

def attribute_distance(attr_vec1, attr_vec2):
    """Calculates the Euclidean distance between two attribute vectors."""
    return np.linalg.norm(attr_vec1 - attr_vec2)

def angular_distance_2d(angle1, angle2):
    """Calculates the shortest angular distance between two angles."""
    delta_angle = abs(angle1 - angle2)
    # The shortest angle between two angles, handling wrap-around at 2*pi
    return min(delta_angle, 2 * math.pi - delta_angle)

def objective_function(angles_flat, category_names, attribute_centroids_map, fixed_radius):
    """
    Objective function to minimize.
    New formula: 1/dist_atr * (2*pi - dist_angl)**2
    Centroids are constrained to a fixed radius, so no penalty for radius.
    """
    current_centroid_angles = {category: angle for category, angle in zip(category_names, angles_flat)}

    total_value_to_minimize = 0.0
    categories = list(attribute_centroids_map.keys())

    # Calculate the sum of terms for all unique pairs
    for i in range(len(categories)):
        for j in range(i + 1, len(categories)):
            cat1 = categories[i]
            cat2 = categories[j]

            angle1 = current_centroid_angles[cat1]
            angle2 = current_centroid_angles[cat2]

            attr1 = attribute_centroids_map[cat1]
            attr2 = attribute_centroids_map[cat2]

            dist_atr = attribute_distance(attr1, attr2)
            # Add a small epsilon to dist_atr to prevent division by zero if attributes are identical
            if dist_atr < 1e-6: # Check if very close to zero
                dist_atr = 1e-6

            dist_angl = angular_distance_2d(angle1, angle2)

            # Apply the new formula: 1/dist_atr * (2*pi - dist_angl)**2
            term = (1 / dist_atr) * ((2 * math.pi - dist_angl)**2)
            total_value_to_minimize += term

    return total_value_to_minimize

def optimize_centroid_placement(attribute_centroids_map, fixed_radius):
    """
    Optimizes the angular positions of category centroids on a fixed radius circle.
    """
    category_names = list(attribute_centroids_map.keys())
    num_categories = len(category_names)

    if num_categories < 2:
        print("Less than 2 categories, no optimization needed for centroid pairs.")
        if num_categories == 1:
            # For a single centroid, place it at (radius, 0)
            return {category_names[0]: (fixed_radius, 0.0)}
        else:
            return {} # No categories

    # Initial guess: Place centroids randomly along the circumference (random angles)
    initial_guess_angles = np.array([random.uniform(0, 2 * math.pi) for _ in range(num_categories)])

    # Define bounds for each angle to keep them within 0 to 2*pi
    bounds = [(0, 2 * math.pi)] * num_categories

    result = minimize(
        objective_function,
        initial_guess_angles,
        args=(category_names, attribute_centroids_map, fixed_radius),
        method='SLSQP', # Suitable for bounded optimization
        bounds=bounds,
        options={'disp': False, 'maxiter': 5000}
    )

    optimized_centroid_positions = {}
    if result.success:
        optimized_angles = result.x
        for i, category in enumerate(category_names):
            # Convert optimized angle back to (x, y) coordinates on the fixed radius
            x = fixed_radius * math.cos(optimized_angles[i])
            y = fixed_radius * math.sin(optimized_angles[i])
            optimized_centroid_positions[category] = (x, y)
    else:
        print(f"Centroid optimization failed: {result.message}")
        print("Falling back to initial random angular placement for centroids.")
        for i, category in enumerate(category_names):
            x = fixed_radius * math.cos(initial_guess_angles[i])
            y = fixed_radius * math.sin(initial_guess_angles[i])
            optimized_centroid_positions[category] = (x, y)

    return optimized_centroid_positions

# --- Main Execution Flow for Centroid Placement ---
attribute_centroids = calculate_attribute_centroids(G)
print("\nAttribute Centroids (High-Dimensional):")
for cat, attr_cent in attribute_centroids.items():
    print(f"  {cat}: {attr_cent[:5]}...") # Print first few elements for brevity

# Optimize the 2D positions for the visual centroids
# This is the primary change in centroid placement logic
centroid_coords = optimize_centroid_placement(attribute_centroids, OPTIMIZATION_RADIUS)
print("\nOptimized 2D Centroid Coordinates (on circumference):")
for cat, pos in centroid_coords.items():
    print(f"  {cat}: {pos}")

# ====================================================================
# END OF MODIFICATIONS ONLY TO CENTROID PLACEMENT LOGIC
# ====================================================================


# --- Node Distribution around Centroids (this part is restored to your exact code) ---
node_positions = {}
perturb_scale = 0.8 # Small perturbation factor to spread nodes around their centroid

lognormal_mu = 0.5   # Mean of the logarithm of the radius (controls average distance)
lognormal_sigma = 0.5 # Standard deviation of the logarithm of the radius (controls spread)
max_radius_cutoff = 1.5 # An upper bound to prevent extremely large radii, crucial with log-normal
# Note: MIN_NODE_DISTANCE from previous iterations was specific to poisson disk,
# but your current node placement uses a simple lognormal offset for each node,
# so MIN_NODE_DISTANCE would not be directly applied here.

# Placeholder for your Poisson Disk Sampling function (modified for log-normal radius)
# This function is used by your existing node distribution loop
def generate_poisson_disk_points_in_circle_lognormal(center_x, center_y, lognormal_mu, lognormal_sigma, max_radius_cutoff, num_points_to_generate):
    # This simplified version does not implement a full Poisson Disk sampling algorithm
    # which ensures minimum distance between points. It applies a log-normal distribution
    # for the radius from the centroid and then assigns points.
    points = []
    for _ in range(num_points_to_generate): # Generate points for each node
        r = np.random.lognormal(lognormal_mu, lognormal_sigma)
        if r > max_radius_cutoff:
            r = max_radius_cutoff # Clamp if too large

        angle = random.uniform(0, 2 * math.pi)
        px = center_x + r * math.cos(angle)
        py = center_y + r * math.sin(angle)
        points.append((px, py))
    return points


for node_id in G.nodes():
    category = G.nodes[node_id]['category']
    cx, cy = centroid_coords[category] # Now uses the optimized centroid_coords

    # Your original lognormal offset for each node:
    initial_r = np.random.lognormal(lognormal_mu, lognormal_sigma)
    if initial_r > max_radius_cutoff:
        initial_r = max_radius_cutoff # Fallback if initial is too large
    initial_angle = random.uniform(0, 2 * math.pi)
    initial_px = cx + initial_r * math.cos(initial_angle)
    initial_py = cy + initial_r * math.sin(initial_angle)
    node_positions[node_id] = (initial_px, initial_py)


print("\nFinal Node Positions calculated.")

# --- 4. Plot the graph with translucent edges and categorized nodes ---
plt.figure(figsize=(15, 12)) # Larger figure size for better visibility

# Draw edges with low alpha for overlap effect
# Using a slightly darker gray for better contrast on possible white background
nx.draw_networkx_edges(G, node_positions, edge_color='#666666', alpha=0.01, width=0.1) # Adjust alpha and width

# Get unique categories and assign colors for nodes using a colormap
unique_categories = sorted(list(set(id_to_category.values()))) # Get unique categories
num_categories = len(unique_categories)
cmap = plt.cm.get_cmap('tab20', num_categories)

# Draw nodes, iterating by category to add labels for the legend
for i, category in enumerate(unique_categories):
    # Filter nodes belonging to the current category
    nodes_in_category = [node for node in G.nodes() if G.nodes[node]['category'] == category]

    # Get positions for these nodes
    pos_in_category = {node: node_positions[node] for node in nodes_in_category}

    # Get color for this category
    color = cmap(i) # Use the index 'i' to get the color from the colormap

    nx.draw_networkx_nodes(G, pos_in_category,
                            nodelist=nodes_in_category, # Specify which nodes to draw
                            node_color=[color] * len(nodes_in_category), # Assign uniform color to all nodes in this category
                            node_size=20, alpha=0.9, linewidths=0.5, edgecolors='black',
                            label=category) # Add label for the legend


# --- 5. Plot the centroids and their labels ---
# Ensure centroid_coords is not empty before plotting
if centroid_coords:
    centroid_x = [p[0] for p in centroid_coords.values()]
    centroid_y = [p[1] for p in centroid_coords.values()]
    centroid_labels = list(centroid_coords.keys())

    #plt.scatter(centroid_x, centroid_y, color='red', marker='X', s=200, zorder=5, label='Category Centroids')
    #for label, (x, y) in centroid_coords.items():
    #    plt.text(x, y, label, fontsize=9, ha='center', va='bottom', color='red', weight='bold')


plt.title(f"Brazilian Politicians Clustered by {chosen_category_column.replace('_', ' ').title()}")
plt.axis('equal') # Ensures the circle looks like a circle
plt.axis('off') # Hide axes for a cleaner graph
plt.legend(loc='upper right', bbox_to_anchor=(1.15, 1)) # Adjust legend position to not overlap graph
plt.show()
